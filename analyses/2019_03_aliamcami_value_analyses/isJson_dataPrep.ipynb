{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/overscripted/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/anaconda3/envs/overscripted/lib/python3.6/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sub samples and new samples with new columns/data will be saved under the \"DIR\" directory to keep things organized. \n",
    "As such, the function \"save_parquet\" and \"read_parquet\" adds this directory to every parquet name, and I'm using this functions instead of dd.read_parquet/dd.to_parquet direct to ensure the same read and write settings across the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing client / distributed\n",
    "# client = Client()\n",
    "# client\n",
    "\n",
    "#Create folder to save/read new data\n",
    "DIR = 'sample_0_prep/'\n",
    "import os\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no \"recalculate_partition\" is passed on, it will not recalculate the partitions. It is not mandatory, but good if you are significantly reducing the size of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a DF to a parquet\n",
    "def save_parquet(df, name, recalculate_partition=False):\n",
    "    with ProgressBar():\n",
    "        #DF.REPARTITION copyed from: https://stackoverflow.com/questions/44657631/strategy-for-partitioning-dask-dataframes-efficiently\n",
    "        if recalculate_partition:\n",
    "            n = 1+df.memory_usage(deep=True).sum().compute() // (1000 * 1000 * 100)\n",
    "            print(\"Npartition: \", n)\n",
    "            df.repartition(npartitions= n).to_parquet(DIR + name, engine=\"pyarrow\")\n",
    "        else:\n",
    "            df.to_parquet(DIR + name, engine=\"pyarrow\")\n",
    "        \n",
    "        \n",
    "def read_parquet(name):\n",
    "    return dd.read_parquet(DIR + name, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Using 10% sample and self produced samples\n",
    " - 10% sample has 11292867 rows\n",
    " - Filtered by value_len > df.mean() has 499805 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['value_1000', 'value', 'value_len', 'symbol', 'script_url', 'location'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original sample\n",
    "df = dd.read_parquet('sample_0.parquet', \n",
    "                     engine='pyarrow', \n",
    "                     columns=['value_1000', 'value', 'value_len', 'symbol', 'script_url', 'location'])\n",
    "\n",
    "# df.astype({'value_1000': str, 'value': str,'value_len': int,'symbol': int,'script_url': str})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF overview\n",
    "Some overview about the sample: \n",
    "- Mean: 1356.97,\n",
    "- Min: 0,\n",
    "- Max: 4496861\n",
    "- Std: 26310.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 48.2s\n",
      "1356.9776628910975 0 4496861 26310.62140481331 11292867\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    df_mean = df['value_len'].mean()\n",
    "    df_min = df['value_len'].min()\n",
    "    df_max = df['value_len'].max()\n",
    "    df_std = df['value_len'].std()\n",
    "    df_len = df['value_len'].count()\n",
    "    (df_mean, df_min, df_max, df_std, df_len) = dd.compute(df_mean, df_min, df_max, df_std, df_len);\n",
    "    print(df_mean, df_min, df_max, df_std, df_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FILTER: value_len > df_mean\n",
    "1356 is the value_len mean\n",
    "\n",
    "To filter the data into something that is more interesting to this task I decided to only work with values that are at above the mean.\n",
    "\n",
    "All values above the mean count up to 499805 rows. That is just 4,42% of the whole sample, and a lot easier to work on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 58.0s\n",
      "Npartition:  244\n",
      "[########################################] | 100% Completed |  1min 30.9s\n"
     ]
    }
   ],
   "source": [
    "#Save\n",
    "save_parquet(df= df[df['value_len'] > df_mean], name='above_mean.parquet', recalculate_partition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['value_1000', 'value', 'value_len', 'symbol', 'script_url', 'location'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read\n",
    "df = read_parquet('above_mean.parquet')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column: Domains\n",
    "The following code is copyed from this same project: ~/analyses/hello_world.ipynb\n",
    "\n",
    "It uses the data saved from the last section\n",
    "This section is dedicated to extract the domain of the columns \"location\" and \"script_url\" and add it as new columns \"location_domain\" and \"script_domain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "\n",
    "def extract_domain(url):\n",
    "    \"\"\"Use tldextract to return the base domain from a url\"\"\"\n",
    "    try:\n",
    "        extracted = tldextract.extract(url)\n",
    "        return '{}.{}'.format(extracted.domain, extracted.suffix)\n",
    "    except Exception as e:\n",
    "        return 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To guarantee the usage of the correct parquet created above in case we start from this section\n",
    "df = read_parquet('above_mean.parquet')\n",
    "\n",
    "df.astype({'value_1000': str, 'value': str,'value_len': int,'symbol': int,'script_url': str, 'location': str})\n",
    "df['location_domain'] = df.location.apply(extract_domain, meta='O')\n",
    "df['script_domain'] = df.script_url.apply(extract_domain, meta='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1min 17.3s\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "save_parquet(df=df, name='above_mean_domain.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_domain</th>\n",
       "      <th>location</th>\n",
       "      <th>script_domain</th>\n",
       "      <th>script_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>canada.ca</td>\n",
       "      <td>https://www.canada.ca/en/services.html</td>\n",
       "      <td>adobedtm.com</td>\n",
       "      <td>https://assets.adobedtm.com/caacec67651710193d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tmall.com</td>\n",
       "      <td>https://maniform.world.tmall.com/category-1282...</td>\n",
       "      <td>alicdn.com</td>\n",
       "      <td>https://g.alicdn.com/alilog/mlog/aplus_v2.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tmall.com</td>\n",
       "      <td>https://maniform.world.tmall.com/category-1282...</td>\n",
       "      <td>alicdn.com</td>\n",
       "      <td>https://g.alicdn.com/alilog/mlog/aplus_v2.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coches.net</td>\n",
       "      <td>https://www.coches.net/fiat/segunda-mano/</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>https://www.coches.net/scripts/common.min.js?2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coches.net</td>\n",
       "      <td>https://www.coches.net/fiat/segunda-mano/</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>https://www.coches.net/scripts/common.min.js?2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_domain                                           location  \\\n",
       "0       canada.ca             https://www.canada.ca/en/services.html   \n",
       "1       tmall.com  https://maniform.world.tmall.com/category-1282...   \n",
       "2       tmall.com  https://maniform.world.tmall.com/category-1282...   \n",
       "3      coches.net          https://www.coches.net/fiat/segunda-mano/   \n",
       "4      coches.net          https://www.coches.net/fiat/segunda-mano/   \n",
       "\n",
       "  script_domain                                         script_url  \n",
       "0  adobedtm.com  https://assets.adobedtm.com/caacec67651710193d...  \n",
       "1    alicdn.com       https://g.alicdn.com/alilog/mlog/aplus_v2.js  \n",
       "2    alicdn.com       https://g.alicdn.com/alilog/mlog/aplus_v2.js  \n",
       "3    coches.net  https://www.coches.net/scripts/common.min.js?2...  \n",
       "4    coches.net  https://www.coches.net/scripts/common.min.js?2...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read\n",
    "df = read_parquet('above_mean_domain.parquet')\n",
    "df[['location_domain',  'location', 'script_domain', 'script_url']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column:  is_json\n",
    "\n",
    "After manual initial analysis I have think that the huge values are json structured, to validate that I included an new column that is a boolean value with the validation of json\n",
    "\n",
    "After simple validation of value is a json or not, boolean value will be saved on a new column named \"is_json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def is_json(myjson):\n",
    "    try:\n",
    "        json.loads(myjson)\n",
    "        return True\n",
    "\n",
    "    except ValueError as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To guarantee the usage of the correct parquet created above in case we start from this section\n",
    "df = read_parquet('above_mean_domain.parquet')\n",
    "df['is_json'] = df['value'].apply(is_json, meta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2min 25.1s\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "save_parquet(df=df, name='above_mean_domain_json.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>is_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000  is_json\n",
       "0  {\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...     True\n",
       "1  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...     True\n",
       "2  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...     True\n",
       "3  usunico=17/12/2017:0-00155123:830; SessionASM=...    False\n",
       "4  usunico=17/12/2017:0-00155123:830; SessionASM=...    False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read\n",
    "df = read_parquet('above_mean_domain_json.parquet')\n",
    "df[['value_1000', 'is_json']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column:  value_md5\n",
    "Include new columns called \"value_md5\" that is the md5 of value column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def md5(value):\n",
    "    return hashlib.md5(value.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To guarantee the usage of the correct parquet created above in case we start from this section\n",
    "df = read_parquet('above_mean_domain_json.parquet') \n",
    "\n",
    "df['value_md5'] = df['value'].apply(md5, meta=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1min 26.8s\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "save_parquet(df=df, name='above_mean_domain_json_md5.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>value_md5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...</td>\n",
       "      <td>cff77029e3ae45dd439a62987b1d8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>9ac0a0a0afb677c8fd985a7c2f4ddbc5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>9ac0a0a0afb677c8fd985a7c2f4ddbc5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>db64465b639e01993d9212390f057628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>db64465b639e01993d9212390f057628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000  \\\n",
       "0  {\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...   \n",
       "1  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...   \n",
       "2  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...   \n",
       "3  usunico=17/12/2017:0-00155123:830; SessionASM=...   \n",
       "4  usunico=17/12/2017:0-00155123:830; SessionASM=...   \n",
       "\n",
       "                          value_md5  \n",
       "0  cff77029e3ae45dd439a62987b1d8340  \n",
       "1  9ac0a0a0afb677c8fd985a7c2f4ddbc5  \n",
       "2  9ac0a0a0afb677c8fd985a7c2f4ddbc5  \n",
       "3  db64465b639e01993d9212390f057628  \n",
       "4  db64465b639e01993d9212390f057628  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read\n",
    "df = read_parquet('above_mean_domain_json_md5.parquet')\n",
    "df[['value_1000', 'value_md5']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving other possible usefull samples to future analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to parquet containing only JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 27.4s\n",
      "Npartition:  233\n",
      "[########################################] | 100% Completed |  1min  3.4s\n"
     ]
    }
   ],
   "source": [
    "df = read_parquet('above_mean_domain_json_md5.parquet')\n",
    "save_parquet(df=df[df['is_json'] == True], name='JSONs_only.parquet', recalculate_partition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>is_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000  is_json\n",
       "0  {\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...     True\n",
       "1  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...     True\n",
       "2  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...     True\n",
       "3  {\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...     True\n",
       "4  {\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...     True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read all_json_above_mean\n",
    "df = read_parquet('JSONs_only.parquet')\n",
    "df[['value_1000', 'is_json']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add json keys and schema columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the top level keys, sort them and add as a list into another column named 'json_keys'\n",
    "Will be using \"https://github.com/rnd0101/json_schema_inferencer\" to guess the json schema and save it into another column called \"json_schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json_schema_inferencer.guess_json_schema import guess_schema\n",
    "\n",
    "df = read_parquet('JSONs_only.parquet')\n",
    "\n",
    "def jsonSchema(myjson):\n",
    "    try:\n",
    "        dct = json.loads(myjson)\n",
    "        value = guess_schema(dct)\n",
    "        l = list(value['properties'])\n",
    "        l.sort()\n",
    "        return l\n",
    "    except ValueError as e:\n",
    "        return list()\n",
    "    \n",
    "def jsonKeys(myjson):\n",
    "    try:\n",
    "        dct = json.loads(myjson)\n",
    "        keys = list(dct.keys())\n",
    "        keys.sort()\n",
    "        return keys\n",
    "    except ValueError as e:\n",
    "        return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3min 57.7s\n"
     ]
    }
   ],
   "source": [
    "df['json_keys'] = df['value'].apply(jsonKeys, meta='')\n",
    "df['json_schema'] = df['value'].apply(jsonSchema, meta='')\n",
    "save_parquet(df=df, name='JSONs_key_schema.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>json_keys</th>\n",
       "      <th>json_schema</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...</td>\n",
       "      <td>[im-settings]</td>\n",
       "      <td>[im-settings]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>[APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c]</td>\n",
       "      <td>[APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>[APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c]</td>\n",
       "      <td>[APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...</td>\n",
       "      <td>[LastSearch, LastSearch_e, dueljs_channel_comm...</td>\n",
       "      <td>[LastSearch, LastSearch_e, dueljs_channel_comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...</td>\n",
       "      <td>[LastSearch, LastSearch_e, dueljs_channel_comm...</td>\n",
       "      <td>[LastSearch, LastSearch_e, dueljs_channel_comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000  \\\n",
       "0  {\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...   \n",
       "1  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...   \n",
       "2  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...   \n",
       "3  {\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...   \n",
       "4  {\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...   \n",
       "\n",
       "                                           json_keys  \\\n",
       "0                                      [im-settings]   \n",
       "1     [APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c]   \n",
       "2     [APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c]   \n",
       "3  [LastSearch, LastSearch_e, dueljs_channel_comm...   \n",
       "4  [LastSearch, LastSearch_e, dueljs_channel_comm...   \n",
       "\n",
       "                                         json_schema  \n",
       "0                                      [im-settings]  \n",
       "1     [APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c]  \n",
       "2     [APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c]  \n",
       "3  [LastSearch, LastSearch_e, dueljs_channel_comm...  \n",
       "4  [LastSearch, LastSearch_e, dueljs_channel_comm...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read \n",
    "df = read_parquet('JSONs_key_schema.parquet')\n",
    "df[['value_1000', 'json_keys', 'json_schema']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All NON json above the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 26.7s\n",
      "Npartition:  12\n",
      "[########################################] | 100% Completed | 27.8s\n"
     ]
    }
   ],
   "source": [
    "df = read_parquet('above_mean_domain_json_md5.parquet')\n",
    "save_parquet(df=df[df['is_json'] == False], name='NON_JSONs_only.parquet', recalculate_partition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>value</th>\n",
       "      <th>value_len</th>\n",
       "      <th>symbol</th>\n",
       "      <th>script_url</th>\n",
       "      <th>location</th>\n",
       "      <th>location_domain</th>\n",
       "      <th>script_domain</th>\n",
       "      <th>is_json</th>\n",
       "      <th>value_md5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>1358</td>\n",
       "      <td>window.document.cookie</td>\n",
       "      <td>https://www.coches.net/scripts/common.min.js?2...</td>\n",
       "      <td>https://www.coches.net/fiat/segunda-mano/</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>False</td>\n",
       "      <td>db64465b639e01993d9212390f057628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>1358</td>\n",
       "      <td>window.document.cookie</td>\n",
       "      <td>https://www.coches.net/scripts/common.min.js?2...</td>\n",
       "      <td>https://www.coches.net/fiat/segunda-mano/</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>False</td>\n",
       "      <td>db64465b639e01993d9212390f057628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>1358</td>\n",
       "      <td>window.document.cookie</td>\n",
       "      <td>https://tags.tiqcdn.com/utag/schibsted/coches....</td>\n",
       "      <td>https://www.coches.net/fiat/segunda-mano/</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>tiqcdn.com</td>\n",
       "      <td>False</td>\n",
       "      <td>db64465b639e01993d9212390f057628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>1358</td>\n",
       "      <td>window.document.cookie</td>\n",
       "      <td>https://tags.tiqcdn.com/utag/schibsted/coches....</td>\n",
       "      <td>https://www.coches.net/fiat/segunda-mano/</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>tiqcdn.com</td>\n",
       "      <td>False</td>\n",
       "      <td>db64465b639e01993d9212390f057628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>usunico=17/12/2017:0-00155123:830; SessionASM=...</td>\n",
       "      <td>1358</td>\n",
       "      <td>window.document.cookie</td>\n",
       "      <td>https://tags.tiqcdn.com/utag/schibsted/coches....</td>\n",
       "      <td>https://www.coches.net/fiat/segunda-mano/</td>\n",
       "      <td>coches.net</td>\n",
       "      <td>tiqcdn.com</td>\n",
       "      <td>False</td>\n",
       "      <td>db64465b639e01993d9212390f057628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000  \\\n",
       "0  usunico=17/12/2017:0-00155123:830; SessionASM=...   \n",
       "1  usunico=17/12/2017:0-00155123:830; SessionASM=...   \n",
       "2  usunico=17/12/2017:0-00155123:830; SessionASM=...   \n",
       "3  usunico=17/12/2017:0-00155123:830; SessionASM=...   \n",
       "4  usunico=17/12/2017:0-00155123:830; SessionASM=...   \n",
       "\n",
       "                                               value  value_len  \\\n",
       "0  usunico=17/12/2017:0-00155123:830; SessionASM=...       1358   \n",
       "1  usunico=17/12/2017:0-00155123:830; SessionASM=...       1358   \n",
       "2  usunico=17/12/2017:0-00155123:830; SessionASM=...       1358   \n",
       "3  usunico=17/12/2017:0-00155123:830; SessionASM=...       1358   \n",
       "4  usunico=17/12/2017:0-00155123:830; SessionASM=...       1358   \n",
       "\n",
       "                   symbol                                         script_url  \\\n",
       "0  window.document.cookie  https://www.coches.net/scripts/common.min.js?2...   \n",
       "1  window.document.cookie  https://www.coches.net/scripts/common.min.js?2...   \n",
       "2  window.document.cookie  https://tags.tiqcdn.com/utag/schibsted/coches....   \n",
       "3  window.document.cookie  https://tags.tiqcdn.com/utag/schibsted/coches....   \n",
       "4  window.document.cookie  https://tags.tiqcdn.com/utag/schibsted/coches....   \n",
       "\n",
       "                                    location location_domain script_domain  \\\n",
       "0  https://www.coches.net/fiat/segunda-mano/      coches.net    coches.net   \n",
       "1  https://www.coches.net/fiat/segunda-mano/      coches.net    coches.net   \n",
       "2  https://www.coches.net/fiat/segunda-mano/      coches.net    tiqcdn.com   \n",
       "3  https://www.coches.net/fiat/segunda-mano/      coches.net    tiqcdn.com   \n",
       "4  https://www.coches.net/fiat/segunda-mano/      coches.net    tiqcdn.com   \n",
       "\n",
       "   is_json                         value_md5  \n",
       "0    False  db64465b639e01993d9212390f057628  \n",
       "1    False  db64465b639e01993d9212390f057628  \n",
       "2    False  db64465b639e01993d9212390f057628  \n",
       "3    False  db64465b639e01993d9212390f057628  \n",
       "4    False  db64465b639e01993d9212390f057628  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read \n",
    "df = read_parquet('NON_JSONs_only.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
